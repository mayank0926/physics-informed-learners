{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "# 3D plotting\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         # Latin Hypercube Sampling\n",
    "import scipy.io               # Loading .mat matlab data \n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Running this on\", device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name()) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running this on cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def main_loop(N_u, N_f, num_layers, num_neurons):\n",
    "     \n",
    "    nu = 0.01/np.pi\n",
    "\n",
    "    layers = np.concatenate([[2], num_neurons*np.ones(num_layers), [1]]).astype(int).tolist()\n",
    "    \n",
    "    data = scipy.io.loadmat('Data/burgers_shock.mat')\n",
    "    \n",
    "    t = data['t'].flatten()[:,None]\n",
    "    x = data['x'].flatten()[:,None]\n",
    "    Exact = np.real(data['usol']).T\n",
    "    \n",
    "    X, T = np.meshgrid(x,t)\n",
    "    \n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    u_star = Exact.flatten()[:,None]              \n",
    "\n",
    "    # Doman bounds\n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)    \n",
    "        \n",
    "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "    uu1 = Exact[0:1,:].T\n",
    "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "    uu2 = Exact[:,0:1]\n",
    "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "    uu3 = Exact[:,-1:]\n",
    "    \n",
    "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "    X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "    u_train = np.vstack([uu1, uu2, uu3])\n",
    "    \n",
    "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "    X_u_train = X_u_train[idx, :]\n",
    "    u_train = u_train[idx,:]\n",
    "        \n",
    "    # model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, nu)\n",
    "    \n",
    "    # start_time = time.time()                \n",
    "    # model.train()\n",
    "    # elapsed = time.time() - start_time                \n",
    "    # print('Training time: %.4f' % (elapsed))\n",
    "    \n",
    "    # u_pred, f_pred = model.predict(X_star)\n",
    "            \n",
    "    # error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "     \n",
    "    error_u = 0   \n",
    "    \n",
    "    return error_u"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "main_loop(20, 2000, 8, 40)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\": \n",
    "        \n",
    "    # Training data\n",
    "    N_u = [20, 40, 60, 80, 100, 200]\n",
    "    \n",
    "    # Collocation points\n",
    "    N_f = [2000, 4000, 6000, 7000, 8000, 10000]\n",
    "    \n",
    "    num_layers = [2,4,6,8]\n",
    "    num_neurons = [10,20,40]    \n",
    "    \n",
    "    error_table_1 = np.zeros((len(N_u), len(N_f)))\n",
    "    error_table_2 = np.zeros((len(num_layers), len(num_neurons)))\n",
    " \n",
    "    # Used to calculate errors across varying number of training-collocation and varying numbur of layers and neurons\n",
    "\n",
    "    for i in range(len(N_u)):\n",
    "        for j in range(len(N_f)):\n",
    "            error_table_1[i,j] = main_loop(N_u[i], N_f[j], num_layers[-1], num_neurons[-1])\n",
    "            \n",
    "    for i in range(len(num_layers)):\n",
    "        for j in range(len(num_neurons)):\n",
    "            error_table_2[i,j] = main_loop(N_u[-1], N_f[-1], num_layers[i], num_neurons[j])\n",
    "            \n",
    "    np.savetxt('Tables/error_table_1.csv', error_table_1, delimiter=' & ', fmt='$%.2e$', newline=' \\\\\\\\\\n')\n",
    "    np.savetxt('Tables/error_table_2.csv', error_table_2, delimiter=' & ', fmt='$%.2e$', newline=' \\\\\\\\\\n')\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('aml-project': conda)"
  },
  "interpreter": {
   "hash": "13d70ffd80bfd7768d19573019a856a328d3df43f54048e55f4ee7100f4d7730"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}